<!--Copyright 2024 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# Hybrid Inference

**Empowering local AI builders with Hybrid Inference**

---

## Why use Hybrid Inference?

Hybrid Inference offers a fast and simple way to offload local generation requirements.

* **VAE Decode:** Quickly decode latents to images without comprimising quality or slowing down your workflow.
* **VAE Encode (coming soon):** Encode images to latents for generation or training.
* **Text Encoders (coming soon):** Compute text embeddings for prompts without comprimising quality or slowing down your workflow.

---

## Key Benefits

- ðŸš€ **Reduced Requirements:** Access powerful models without expensive hardware.
- ðŸŽ¯ **Diverse Use Cases:** Fully compatible with Diffusers ðŸ§¨ and the wider community.
- ðŸ”§ **Developer-Friendly:** Simple requests, fast responses.

---

## Contents

The documentation is organized into two sections:

* **Getting Started** Learn the basics of how to use Hybrid Inference.
* **API Reference** Dive into task-specific settings and parameters.
